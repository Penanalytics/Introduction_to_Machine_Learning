{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   > ## Importation des librairies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Importation des algorithmes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets #sklearn est une mine d'or pour faire du machine learning dans Python.\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Importation du jeu de donnees et description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "#On doit definir quel jeu de donnees precisement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=load_iris()\n",
    "# On installe le jeu de donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.keys()# les attributs du jeu de donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (iris.DESCR) # Description du jeu de donnees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A quoi cela ressemble?\n",
    "#Notez que Python commence a 0, pas 1. Donc quand vous voulez sortir les 3 premieres rangees, commencez a 0.\n",
    "print (iris.feature_names)\n",
    "print (iris.data[0:3])\n",
    "print (iris.target[0:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Definition de la variable a predire:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris = pd.DataFrame(iris.data,columns=iris.feature_names)#Transposons nos 10 features dans une dataframe: colonnes et rangees\n",
    "df_iris['target'] = pd.Series(iris.target)# Transposons notre variable a predire dans une serie\n",
    "y = iris.target #Definissons y comme etant notre variable a predire. y ici est une donnee quantitative certes 0,1,2,3... qui vise a classifier l'appartenance a telle ou telle classe.\n",
    "df_iris.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Exploration des donnees ou EDA: Exploratory Data Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_iris, kind=\"reg\") #Observons la linearite ou pas de toutes nos variables les unes comparees aux autres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition de x et y\n",
    "X=iris.data\n",
    "y=iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Standardisons nos donnees\n",
    "La plupart des algorithmes de machine learning fonctionnent \"mieux\" lorsque les donnees sont standardisees ou normalisees.\n",
    "Qu'est ce que la standardisation/normalisation des donnees? Et pourquoi pensez-vous que c'est important? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reponses:\n",
    "> ##### Formules mathematiques: \n",
    "\n",
    ">  1) Standardisation: (x- moyenne x)/ecart-type\n",
    "\n",
    ">  2) Normalisation: (x-valeur min x)/(valeur max x -valeur min x)\n",
    "\n",
    "> Beaucoup d'algorithmes utilisent le concept de distance et donc si certaines variables x ont de tres grandes valeurs eloignees les unes des autres, cela peut fausser le processus d'apprentissage.\n",
    "\n",
    "> L'algorithme KNN compare la distance (mathematique) entre les coordonnees x de l'observation dont on veut predire la classe (dans le jeu de donnees test) par rapport aux k autres observations dans le jeu de donnees d'apprentissage. La classe attribuee a l'observation en question est la classe majoritaire des k observations. \n",
    "> Quand il y a plusieurs x, (variables independentes) et que celles-ci sont ont des valeurs tres eloignees les unes des autres par exemple la masse et les degres pour predire l'appartenance a telle ou telle categories d'etoiles...Les valeurs masse varient entre 10^29 et 10^32, les valeurs temperatures varient entre 6000 degres et 100000 degres. Dans le calcul de la distance les valeurs masse vont tres largement dominer ce qui fait les valeurs degres ne vont presque pas compter.\n",
    "\n",
    "> Tout ca pour expliquer le fonctionnement de KNN (simple) et pour demontrer l'importance des \"distances\".\n",
    "\n",
    "> Sachez qu'il existe plusieurs distances mathematiques: Euclidean, Manhattan, Minkowski. NB: Euclidean (la plus utilisee est Minkowski ou p=2 et Manhattan quand p=1). KNN a tendance a utiliser la distance euclidienne. \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importons donc une classe destinee a standardiser nos donnees, nous allons ici utiliser la standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "Xss = scaler.fit_transform(X)\n",
    "Xss = pd.DataFrame(data=Xss,columns= iris['feature_names'][:4])\n",
    "Xss.describe()\n",
    "Xss.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Demarrage de la phase d'apprentissage (ici de stockage): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C'est la ou la partie learning de Machine Learning rentre en scene!**\n",
    "\n",
    "Remarquez aussi **split**, cela signifie que l'on va diviser notre jeu de donnee en deux: une partie pour la premiere phase qui correspond a la phase d'**'entrainement** de la machine et l'autre partie pour **tester** si ce que la machine aura appris est fiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Xss, y, test_size=0.5, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (X_train.shape)\n",
    "print (X_test.shape)\n",
    "print (y_train.shape)\n",
    "print (y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation du modele KNN sur le jeu de donnees: ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### On cree le modele. ici on decide que l'on va tenir compte de deux voisins.\n",
    "Xss = KNeighborsClassifier(n_neighbors=2, weights='uniform')\n",
    "\n",
    "# On Fit/installe le modele sur notre jeu de donnees test\n",
    "Xss.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "pred1 = Xss.predict(X_test)\n",
    "print( Xss.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Evaluation du modele:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### 1) Calcul du score du modele:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( Xss.score(X_test, y_test))\n",
    "# A votre avis, comment est calcule le score?\n",
    "#le score est ce que l'on appelle: accuracy qui est le % de predictions correctes sur toutes les predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Autre facon de calculer le score \n",
    "print(metrics.accuracy_score(y_test, pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### 2) Calcul de la valeur optimale de k:\n",
    "k=1 apparait risque car on ne base notre prediction que sur une autre seule valeur meme si certes elle est proche\n",
    "k=nombre d'observations est risque aussi car on encourt le risque d'attribuer la classe qui est majoritaire dans notre ensemble de donnees ce qui ne tient pas compte du concept de distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = range(1, len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in k_range:\n",
    "    Xss = KNeighborsClassifier(n_neighbors=k, weights='uniform')\n",
    "\n",
    "    # Fit the model\n",
    "    Xss.fit(X_train, y_train)\n",
    "    \n",
    "    # Assess\n",
    "    scores[k] = Xss.score(X_test, y_test)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### 3) Calcul de l'erreur du modele de base:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### En classification, le modele de base est celui qui predit automatiquement l'appartenance a la classe majoritaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ici, nous transformons le format de y_test et passons d'une liste/tableau a une serie et ce pour pouvoir utiliser certaines\n",
    "#fonctionnalites\n",
    "np_array_y_test = y_test\n",
    "print(\"NumPy array:\")\n",
    "print(np_array_y_test)\n",
    "new_series_y_test = pd.Series(np_array_y_test)\n",
    "print(\"Converted Pandas series:\")\n",
    "print(new_series_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ici,nous regardons quelle est la classe majoritaire:0?1?2?\n",
    "#On observe que la classe majoritaire est 0.\n",
    "new_series_y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ici, on cree notre modele de base qui va predire l'appartenance a la classe majoritaire dans 100% des cas.\n",
    "baseline=new_series_y_test.value_counts().head(1)/len(new_series_y_test)#Cette formule retourne la proportion de la classe majoritaire.\n",
    "baseline\n",
    "#La classe majoritaire est majoritaire a 38%. Donc le niveau de precision du modele est de 38%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
